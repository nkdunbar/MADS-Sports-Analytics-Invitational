{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc9d7f6-ea88-4d2f-8a75-90af536b053c",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "\n",
    "Old testing notebooks are messy, but located in the 'Old Testing and Notes' folder, which contain previous attempts at feature transformation and model tuning. RandomForestRegressor parameters were determined from a GridSearchCV over a portion of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ba25d8-426a-4cf9-a225-05f483eda20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "events=df['event.id'].unique()\n",
    "\n",
    "train_set=events[0:100]\n",
    "test_set=events[100:200]\n",
    "holdout_set=events[200:300]\n",
    "\n",
    "train=df.query(\"`event.id` in @train_set\")\n",
    "test=df.query(\"`event.id` in @test_set\")\n",
    "holdout=df.query(\"`event.id` in @holdout_set\")\n",
    "\n",
    "# You notice how I just hard coded some slices in and made the sets the same\n",
    "# size. You don't have to do this, and in the end, you want to submit your models\n",
    "# to the autograder using *all* of the data in this dataset. But this is real\n",
    "# world data so there will be weird format errors, and having a clear holdout\n",
    "# set will give you a chance to \"fail fast\" and see those errors crop up without\n",
    "# having to submit to the autograder\n",
    "    \n",
    "# Speaking about the holdout dataset, it will not have a bunch of data in it, like\n",
    "# race times. That would of course leak the results, and wouldn't be available in\n",
    "# practice. The addendum to the assignment has this description, and I just copy\n",
    "# and past it here and create the same thing. This ensures when I am playing with\n",
    "# my models and then want to evaluate them I won't make a mistake and use a\n",
    "# column incorrectly.\n",
    "\n",
    "holdout=holdout.drop(\n",
    "    columns=['time.end',\n",
    "             'body.results_certificate',\n",
    "             'event.results_posted',\n",
    "             'event.results_posted',\n",
    "             'event.results_certificate',\n",
    "             'event.photos_available',\n",
    "             'event.photos_faces',\n",
    "             'event.photos_social_sharing',\n",
    "             'event.results_searchable',\n",
    "             'corral.id',\n",
    "             'corral.name',\n",
    "             'corral.wave',\n",
    "             'corral.time.close',\n",
    "             'corral.time.start',\n",
    "             'result.duration.chip',\n",
    "             'result.duration.pace',\n",
    "             'result.rankings',\n",
    "             'result.splits',\n",
    "             'result.videos',\n",
    "             'result.finished',\n",
    "             'result.disqualified',\n",
    "             'result.duration'])\n",
    "\n",
    "# Also, I will garuntee in the holdout set there is data. At least 6 rows per race\n",
    "holdout=df.groupby([\"event.id\",\"clean_categories.name\"]).filter(lambda z: len(z)>5)\n",
    "\n",
    "y=pd.to_timedelta(df['result.duration.chip']).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bb4c3-a4fc-4c3e-9ce4-1a9a0c81b606",
   "metadata": {},
   "source": [
    "### Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4f6b56-a787-46dc-9710-853ed82462cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "\n",
    "# This code simulates the autograder. It is not the full autograder implementation\n",
    "# but shares an API with the autograder. It expects that your fitted pipeline is\n",
    "# submitted with the name pipeline.cloudpickle as demonstrated above. This object\n",
    "# must implement the predict() function. This is done automatically by the sklearn\n",
    "# Pipeline object if the last element of your pipeline is a classifier which has\n",
    "# a predict() function. If you are not submitting a Pipeline, and want to do something\n",
    "# different, you *must* have a predict() function of the same method signature, e.g.:\n",
    "#\n",
    "#   predict(self, X, **predict_params)->np.ndarray\n",
    "\n",
    "# Load holdout data, in this case I'll simulate it by loading the training data\n",
    "#df=pd.read_csv(\"../../assets/assignment/df_train.csv.gz\")\n",
    "\n",
    "# And evaluate on all 5k races that we didn't consider for training\n",
    "#holdout_data=df.query(\"`event.id`!='583f013a-1e54-4906-87f7-2b625206f5f9' and `clean_categories.name`=='5k'\")\n",
    "holdout_data=holdout\n",
    "\n",
    "# This is the scoring function to determine model fitness\n",
    "def score(left: pd.DataFrame, right: pd.DataFrame):\n",
    "    '''\n",
    "    Calculates the difference between the left and the right when considering rank of items. \n",
    "    This scoring function requires that the two DataFrames have identical indicies, and that\n",
    "    they each contain only one column of values and no missing values. Props to Blake Atkinson\n",
    "    for providing MWE indicating issues with autograder version #1.\n",
    "    '''\n",
    "    assert(type(left)==pd.DataFrame)\n",
    "    assert(type(right)==pd.DataFrame)\n",
    "    assert(len(left)==len(right))\n",
    "    assert(not np.any(np.isnan(left)))\n",
    "    assert(not np.any(np.isnan(right)))\n",
    "    assert(left.index.equals(right.index))\n",
    "    # convert to ndarrays\n",
    "    left=left.squeeze()\n",
    "    right=right.squeeze()\n",
    "    return np.sum(np.abs(left-right))/(len(left)*(len(left)-1))\n",
    "\n",
    "# This function runs the prediction model agains a given event/category pair. It\n",
    "# intentionally loads the student model each time to avoid accidental leakage of data\n",
    "# between events.\n",
    "def evaluate(data, pipeline_file='pipeline.cloudpickle'):\n",
    "    # Load student pipeline\n",
    "    fitted_pipe = cloudpickle.load(open(pipeline_file,'rb'))\n",
    "    \n",
    "    # Separate out the X and y\n",
    "    X=list(set(data.columns)-{'overall_ranking'})\n",
    "    y=['overall_ranking']\n",
    "    \n",
    "    # Drop any missing results (DNFs)\n",
    "    data=data.dropna(subset=['overall_ranking'])\n",
    "    \n",
    "    # Ensure there is data to actually predict on\n",
    "    if len(data)==0:\n",
    "        return np.nan\n",
    "\n",
    "    # Predict on unseen data\n",
    "    from IPython.utils import io\n",
    "    with io.capture_output() as captured:\n",
    "        predictions=pd.DataFrame(fitted_pipe.predict(data[X]),data.index)\n",
    "    observed=data[y]\n",
    "    \n",
    "    # Generate rankings within this bracket\n",
    "    observed=pd.DataFrame(data[y].rank(),data.index)\n",
    "    \n",
    "    # Return the ratio of the student score\n",
    "    return pd.Series({\"score\":score(observed,predictions)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b30c0-0a63-474f-a8d5-a92aed558617",
   "metadata": {},
   "source": [
    "### Generate Pipeline and Test Against Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6d5b882-ed14-4151-b5cb-4cfe484d4271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 {color: black;background-color: white;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 pre{padding: 0;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-toggleable {background-color: white;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-estimator:hover {background-color: #d4ebff;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-item {z-index: 1;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-parallel-item:only-child::after {width: 0;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-03ab97ef-735b-4214-a73f-a4ac991c0c72 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-03ab97ef-735b-4214-a73f-a4ac991c0c72\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;category_name&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;clean_category.completed.name&#x27;]),\n",
       "                                                 (&#x27;state&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;location.state&#x27;])])),\n",
       "                (&#x27;simpleimputer&#x27;, SimpleImputer(missing_values=-1)),\n",
       "                (&#x27;quantiletransformer&#x27;, QuantileTransformer()),\n",
       "                (&#x27;transformedtargetregressor&#x27;,\n",
       "                 TransformedTargetRegressor(inverse_func=&lt;function evaluation_function at 0x7f364424be50&gt;,\n",
       "                                            regressor=RandomForestRegressor(max_depth=3,\n",
       "                                                                            min_samples_split=3,\n",
       "                                                                            n_estimators=1000,\n",
       "                                                                            n_jobs=-1)))],\n",
       "         verbose=True)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"73cb9dc6-ade0-47ef-a493-b5c119621203\" type=\"checkbox\" ><label for=\"73cb9dc6-ade0-47ef-a493-b5c119621203\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;customtransformer&#x27;, CustomTransformer()),\n",
       "                (&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;category_name&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;clean_category.completed.name&#x27;]),\n",
       "                                                 (&#x27;state&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False),\n",
       "                                                  [&#x27;location.state&#x27;])])),\n",
       "                (&#x27;simpleimputer&#x27;, SimpleImputer(missing_values=-1)),\n",
       "                (&#x27;quantiletransformer&#x27;, QuantileTransformer()),\n",
       "                (&#x27;transformedtargetregressor&#x27;,\n",
       "                 TransformedTargetRegressor(inverse_func=&lt;function evaluation_function at 0x7f364424be50&gt;,\n",
       "                                            regressor=RandomForestRegressor(max_depth=3,\n",
       "                                                                            min_samples_split=3,\n",
       "                                                                            n_estimators=1000,\n",
       "                                                                            n_jobs=-1)))],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b1b905e1-b441-4e84-9e3b-51df8e4d47de\" type=\"checkbox\" ><label for=\"b1b905e1-b441-4e84-9e3b-51df8e4d47de\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2a127e8f-de7d-46fc-b482-d00ec17e988e\" type=\"checkbox\" ><label for=\"2a127e8f-de7d-46fc-b482-d00ec17e988e\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;category_name&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 [&#x27;clean_category.completed.name&#x27;]),\n",
       "                                (&#x27;state&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=False),\n",
       "                                 [&#x27;location.state&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ccb3bd09-471e-4d06-81e7-a4619cbc9a23\" type=\"checkbox\" ><label for=\"ccb3bd09-471e-4d06-81e7-a4619cbc9a23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">category_name</label><div class=\"sk-toggleable__content\"><pre>[&#x27;clean_category.completed.name&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"190b3928-6944-4605-8d2a-39a384197bf7\" type=\"checkbox\" ><label for=\"190b3928-6944-4605-8d2a-39a384197bf7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0f87b8ec-baad-437f-a5af-b31a910b5c7c\" type=\"checkbox\" ><label for=\"0f87b8ec-baad-437f-a5af-b31a910b5c7c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">state</label><div class=\"sk-toggleable__content\"><pre>[&#x27;location.state&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"17b0fd15-5a21-47cb-ae90-92090377df99\" type=\"checkbox\" ><label for=\"17b0fd15-5a21-47cb-ae90-92090377df99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"bca70eb8-c7d3-4abb-bbb8-a260e5c6c0e7\" type=\"checkbox\" ><label for=\"bca70eb8-c7d3-4abb-bbb8-a260e5c6c0e7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(missing_values=-1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"924f8205-a810-43d2-8914-4c6469fe53f0\" type=\"checkbox\" ><label for=\"924f8205-a810-43d2-8914-4c6469fe53f0\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">QuantileTransformer</label><div class=\"sk-toggleable__content\"><pre>QuantileTransformer()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"6f13b3a0-f7ce-4a83-9b94-c2e005275f61\" type=\"checkbox\" ><label for=\"6f13b3a0-f7ce-4a83-9b94-c2e005275f61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">transformedtargetregressor: TransformedTargetRegressor</label><div class=\"sk-toggleable__content\"><pre>TransformedTargetRegressor(inverse_func=&lt;function evaluation_function at 0x7f364424be50&gt;,\n",
       "                           regressor=RandomForestRegressor(max_depth=3,\n",
       "                                                           min_samples_split=3,\n",
       "                                                           n_estimators=1000,\n",
       "                                                           n_jobs=-1))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4f658402-1046-484e-8753-50c48b27306c\" type=\"checkbox\" ><label for=\"4f658402-1046-484e-8753-50c48b27306c\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=3, min_samples_split=3, n_estimators=1000,\n",
       "                      n_jobs=-1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('customtransformer', CustomTransformer()),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('category_name',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['clean_category.completed.name']),\n",
       "                                                 ('state',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse=False),\n",
       "                                                  ['location.state'])])),\n",
       "                ('simpleimputer', SimpleImputer(missing_values=-1)),\n",
       "                ('quantiletransformer', QuantileTransformer()),\n",
       "                ('transformedtargetregressor',\n",
       "                 TransformedTargetRegressor(inverse_func=<function evaluation_function at 0x7f364424be50>,\n",
       "                                            regressor=RandomForestRegressor(max_depth=3,\n",
       "                                                                            min_samples_split=3,\n",
       "                                                                            n_estimators=1000,\n",
       "                                                                            n_jobs=-1)))],\n",
       "         verbose=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 5) Processing customtransformer, total=   0.7s\n",
      "[Pipeline] . (step 2 of 5) Processing columntransformer, total=   0.4s\n",
      "[Pipeline] ..... (step 3 of 5) Processing simpleimputer, total=   0.5s\n",
      "[Pipeline]  (step 4 of 5) Processing quantiletransformer, total=   2.2s\n",
      "[Pipeline]  (step 5 of 5) Processing transformedtargetregressor, total= 1.2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score    0.267341\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "pd.options.display.max_seq_items = 2000\n",
    "pd.set_option('display.max_columns', 1000)  # or 1000\n",
    "\n",
    "#y=pd.to_timedelta(train['result.duration.chip']).astype(int) #Uncomment to test on training set\n",
    "\n",
    "y=pd.to_timedelta(df['result.duration.chip']).astype(int) #Uncomment to test on full set\n",
    "\n",
    "class CustomTransformer(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        # Just select the features we want\n",
    "        df=X[[\"age\",\"sex\",\"category.completed.distance.quantity\",\n",
    "              \"category.completed.distance.unit\",\"price\",\"fundraising.goal\",\n",
    "              \"clean_category.completed.name\",\"location.state\",\"bib\"]]                   # EDIT FEATURES HERE <-------\n",
    "        \n",
    "        \n",
    "        #category.completed.distance.quantity\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '1 mile fun run/walk'\").index, 'category.completed.distance.quantity']=1.609\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '1 mile run'\").index, 'category.completed.distance.quantity']=1.609\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '10k scenic challenge'\").index, 'category.completed.distance.quantity']=10.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '5k'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '5 km run'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '5k run'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '5k walk/run'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '5k run/walk'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '8k'\").index, 'category.completed.distance.quantity']=8.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '10k'\").index, 'category.completed.distance.quantity']=10.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == '10k run'\").index, 'category.completed.distance.quantity']=10.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'commitment day 5k - master'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'life time commitment day 5k'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'olympic duathlon'\").index, 'category.completed.distance.quantity']=10.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'olympic triathlon'\").index, 'category.completed.distance.quantity']=10.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'one mile fun run'\").index, 'category.completed.distance.quantity']=1.609\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'quarter marathon'\").index, 'category.completed.distance.quantity']=10.55\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'half marathon'\").index, 'category.completed.distance.quantity']=21.1\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'sprint duathlon'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'sprint triathlon'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        df.loc[df.query(\"`clean_category.completed.name` == 'midnight streak'\").index, 'category.completed.distance.quantity']=5.0\n",
    "        \n",
    "        #Clean sex category\n",
    "        df.loc[df.query(\"`sex` == 'Male'\").index, 'sex']=1\n",
    "        df.loc[df.query(\"`sex` == 'M'\").index, 'sex']=1\n",
    "        df.loc[df.query(\"`sex` == 'Female'\").index, 'sex']=0\n",
    "        df.loc[df.query(\"`sex` == 'F'\").index, 'sex']=0\n",
    "        df.loc[df.query(\"`sex` not in [0,1]\").index, 'sex']=np.nan\n",
    "\n",
    "        #Change all completed distances to KM\n",
    "        df.loc[df['category.completed.distance.unit'] == 'mi', 'category.completed.distance.quantity'] *= 1.609\n",
    "        df = df.drop(['category.completed.distance.unit'], axis=1)\n",
    "\n",
    "        #Upper limit on ages\n",
    "        df.loc[df.query(\"`age` > 99\").index, 'age'] = -1\n",
    "\n",
    "        #fundraising.goal\n",
    "        df['fundraising.goal'] = df['fundraising.goal'].fillna(0)\n",
    "        df['fundraising.goal'] = df['fundraising.goal'].astype(str)\n",
    "        df['fundraising.goal'] = df['fundraising.goal'].str.replace('$','')\n",
    "        df['fundraising.goal'] = df['fundraising.goal'].str.replace(',','')\n",
    "        df['fundraising.goal'] = df['fundraising.goal'].astype(float)\n",
    "        \n",
    "        df=df.fillna(-1)\n",
    "        \n",
    "        \n",
    "        return df\n",
    "\n",
    "def evaluation_function(x):\n",
    "    #display(pd.Series(x.squeeze()).rank())\n",
    "    return pd.Series(x.squeeze()).rank().values\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "reg=TransformedTargetRegressor(regressor=RandomForestRegressor(max_depth=3, min_samples_split=3, n_estimators=1000, n_jobs=-1), inverse_func=evaluation_function)\n",
    "#reg.original_predict=reg.predict\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "    ('category_name', OneHotEncoder(sparse=False, drop=None, handle_unknown='ignore'), ['clean_category.completed.name']),\n",
    "    ('state', OneHotEncoder(sparse=False, drop=None, handle_unknown='ignore'), ['location.state'])])\n",
    "\n",
    "# Build the pipeline\n",
    "pipe = make_pipeline(CustomTransformer(), transformer, SimpleImputer(missing_values=-1), QuantileTransformer(), reg, verbose=True) #Removed to reduce filesize: KNNImputer(missing_values=-1)\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display=\"diagram\")\n",
    "display(pipe)\n",
    "\n",
    "fitted_pipe=pipe.fit(df,y)\n",
    "\n",
    "\n",
    "cloudpickle.dump(fitted_pipe, open('pipeline.cloudpickle','wb'))\n",
    "\n",
    "evaluate(holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11cf5d-42d4-48ba-b3d0-00e6cf63f807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
